{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking_Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/castellwhite/MoviesClassification/blob/master/Stacking_Model.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "upa5WLRoYwdI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "# Movies Classification Project\n",
        "</center></h4> <h4>\n",
        " <img src=\"http://usblogs.pwc.com/emerging-technology/wp-content/uploads/2017/07/deep-learning-900x280.png\" >\n",
        "\n",
        "\n",
        "# Machine Learning\n",
        "\n",
        "</h4>\n",
        "\n",
        "Developed by [Sergio Castelblanco](http://www.linkedin.com/in/sergio-castelblanco/) - [Jesus Solano](http://www.jesussolano.com)\n",
        "\n",
        "Andes University\n",
        "\n",
        "version 2.1, July 9 2018"
      ]
    },
    {
      "metadata": {
        "id": "BEYmQ1TEafPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "30301326-5096-462a-82b9-49989ce96bdb"
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "!pip install livelossplot"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.23.4)\n",
            "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot) (2.1.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2018.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.14.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.3.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.3.2)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (2.10)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.2.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.3.1)\n",
            "Requirement already satisfied: mistune>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.8.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.2.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.3.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot) (1.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot) (16.0.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot) (1.0.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (39.1.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.15)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n",
            "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sYPR5ueaLAPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "218d8289-c38a-4c9b-b91c-5b4bf9179caa"
      },
      "cell_type": "code",
      "source": [
        "dataTraining = pd.read_csv('https://github.com/castellwhite/MoviesClassification/blob/master/datasets/dataTraining.csv?raw=true', encoding='UTF-8', index_col=0)\n",
        "dataTesting = pd.read_csv(\"https://github.com/castellwhite/MoviesClassification/blob/master/datasets/dataTesting.csv?raw=true\", encoding='UTF-8', index_col=0)\n",
        "dataTesting.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3383, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "jhKCAKD5YwdK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import r2_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvkivrC7KoSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7e499c82-3eb6-49ef-f416-53ae594378ba"
      },
      "cell_type": "code",
      "source": [
        "rm -r*"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: invalid option -- '*'\r\n",
            "Try 'rm --help' for more information.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sWWWzImUYwdO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Read Data"
      ]
    },
    {
      "metadata": {
        "id": "rEY2WhO7YwdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "1799d76d-48a3-4404-943d-f4c0e8de4802"
      },
      "cell_type": "code",
      "source": [
        "# If datasets already exist do nothing. \n",
        "\n",
        "\n",
        "if not os.path.exists('dataTesting.csv'):\n",
        "  ! wget https://raw.githubusercontent.com/castellwhite/MoviesClassification/master/datasets/dataTesting.csv\n",
        "    \n",
        "if not os.path.exists('dataTraining.csv'):\n",
        "  ! wget https://raw.githubusercontent.com/castellwhite/MoviesClassification/master/datasets/dataTraining.csv\n",
        "    \n",
        "\n",
        "if not os.path.exists('images_resize_color.zip'):\n",
        "  # Install the PyDrive wrapper & import libraries.\n",
        "  # This only needs to be done once per notebook.\n",
        "  !pip install -U -q PyDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "\n",
        "  # Authenticate and create the PyDrive client.\n",
        "  # This only needs to be done once per notebook.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  # Download a file based on its file ID(Grey).\n",
        "  #\n",
        "  # A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "  file_id = '1ZzSvFeCsLVW4hPWqyf6jW0rAvyQt1L7J'\n",
        "  downloaded = drive.CreateFile({'id': file_id})\n",
        "  downloaded.GetContentFile(downloaded['title'])\n",
        "  !unzip -q images_resize_gray.zip \n",
        "\n",
        "  # Download a file based on its file ID(Color).\n",
        "  #\n",
        "  # A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "  # id 160x256 95 : 1ZO1wPtxWfnthbm2NrXt4ca1ZvuxQWD_r\n",
        "  #file_id = '1hAOuBMKUJDiyaHz6fVkwwSAHkmEVNvmP'\n",
        "  \n",
        "  #file_id = '1ZO1wPtxWfnthbm2NrXt4ca1ZvuxQWD_r'\n",
        "  #downloaded = drive.CreateFile({'id': file_id})\n",
        "  #downloaded.GetContentFile(downloaded['title'])\n",
        "  #!unzip -q images_resize_color.zip \n",
        "\n",
        "dataTraining = pd.read_csv(\"dataTraining.csv\",index_col=0)\n",
        "dataTesting = pd.read_csv(\"dataTesting.csv\",index_col=0)\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\r\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
            "replace images_resize_gray/11_resize_gray.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5f_sjXFRYwdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "48e43401-ddd4-4d7f-86f6-4fae225bb6c0"
      },
      "cell_type": "code",
      "source": [
        "dataTraining.head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>plot</th>\n",
              "      <th>genres</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3107</th>\n",
              "      <td>2003</td>\n",
              "      <td>Most</td>\n",
              "      <td>most is the story of a single father who takes...</td>\n",
              "      <td>['Short', 'Drama']</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>900</th>\n",
              "      <td>2008</td>\n",
              "      <td>How to Be a Serial Killer</td>\n",
              "      <td>a serial killer decides to teach the secrets o...</td>\n",
              "      <td>['Comedy', 'Crime', 'Horror']</td>\n",
              "      <td>5.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6724</th>\n",
              "      <td>1941</td>\n",
              "      <td>A Woman's Face</td>\n",
              "      <td>in sweden ,  a female blackmailer with a disfi...</td>\n",
              "      <td>['Drama', 'Film-Noir', 'Thriller']</td>\n",
              "      <td>7.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4704</th>\n",
              "      <td>1954</td>\n",
              "      <td>Executive Suite</td>\n",
              "      <td>in a friday afternoon in new york ,  the presi...</td>\n",
              "      <td>['Drama']</td>\n",
              "      <td>7.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2582</th>\n",
              "      <td>1990</td>\n",
              "      <td>Narrow Margin</td>\n",
              "      <td>in los angeles ,  the editor of a publishing h...</td>\n",
              "      <td>['Action', 'Crime', 'Thriller']</td>\n",
              "      <td>6.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      year                      title  \\\n",
              "3107  2003                       Most   \n",
              "900   2008  How to Be a Serial Killer   \n",
              "6724  1941             A Woman's Face   \n",
              "4704  1954            Executive Suite   \n",
              "2582  1990              Narrow Margin   \n",
              "\n",
              "                                                   plot  \\\n",
              "3107  most is the story of a single father who takes...   \n",
              "900   a serial killer decides to teach the secrets o...   \n",
              "6724  in sweden ,  a female blackmailer with a disfi...   \n",
              "4704  in a friday afternoon in new york ,  the presi...   \n",
              "2582  in los angeles ,  the editor of a publishing h...   \n",
              "\n",
              "                                  genres  rating  \n",
              "3107                  ['Short', 'Drama']     8.0  \n",
              "900        ['Comedy', 'Crime', 'Horror']     5.6  \n",
              "6724  ['Drama', 'Film-Noir', 'Thriller']     7.2  \n",
              "4704                           ['Drama']     7.4  \n",
              "2582     ['Action', 'Crime', 'Thriller']     6.6  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "A-I0t0arYwdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "0b209e5c-28fa-40a2-ea3a-b1984ddde61a"
      },
      "cell_type": "code",
      "source": [
        "dataTesting.head()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>plot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1999</td>\n",
              "      <td>Message in a Bottle</td>\n",
              "      <td>who meets by fate ,  shall be sealed by fate ....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1978</td>\n",
              "      <td>Midnight Express</td>\n",
              "      <td>the true story of billy hayes ,  an american c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1996</td>\n",
              "      <td>Primal Fear</td>\n",
              "      <td>martin vail left the chicago da ' s office to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1950</td>\n",
              "      <td>Crisis</td>\n",
              "      <td>husband and wife americans dr .  eugene and mr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1959</td>\n",
              "      <td>The Tingler</td>\n",
              "      <td>the coroner and scientist dr .  warren chapin ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year                title  \\\n",
              "1  1999  Message in a Bottle   \n",
              "4  1978     Midnight Express   \n",
              "5  1996          Primal Fear   \n",
              "6  1950               Crisis   \n",
              "7  1959          The Tingler   \n",
              "\n",
              "                                                plot  \n",
              "1  who meets by fate ,  shall be sealed by fate ....  \n",
              "4  the true story of billy hayes ,  an american c...  \n",
              "5  martin vail left the chicago da ' s office to ...  \n",
              "6  husband and wife americans dr .  eugene and mr...  \n",
              "7  the coroner and scientist dr .  warren chapin ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "hZH34KymYwdd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Images"
      ]
    },
    {
      "metadata": {
        "id": "5WM-3d6LYwdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "4cad0d21-9dd0-4ac0-eb5b-75eec33e86c5"
      },
      "cell_type": "code",
      "source": [
        "# Load all grey images.\n",
        "\n",
        "print('\\nLoading images for traning...')\n",
        "\n",
        "trainingImagesGrey = []\n",
        "for i in tqdm(dataTraining.index):\n",
        "    trainingImagesGrey.append(io.imread(os.path.join('images_resize_gray', str(i) + '_resize_gray.jpeg')).flatten())\n",
        "    \n",
        "trainingImagesGrey = np.stack(trainingImagesGrey)\n",
        "\n",
        "print('\\nLoading images for testing...')\n",
        "\n",
        "testingImagesGrey = []\n",
        "for i in tqdm(dataTesting.index):\n",
        "    testingImagesGrey.append(io.imread(os.path.join('images_resize_gray', str(i) + '_resize_gray.jpeg')).flatten())\n",
        "\n",
        "testingImagesGrey = np.stack(testingImagesGrey)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 175/7895 [00:00<00:04, 1746.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading images for traning...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7895/7895 [00:05<00:00, 1533.25it/s]\n",
            "  5%|▍         | 166/3383 [00:00<00:01, 1650.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading images for testing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3383/3383 [00:02<00:00, 1572.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IgZU7UGZYweF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Apply PCA to soft analysis.\n",
        "\n",
        "pca = PCA(n_components=32)\n",
        "\n",
        "trainingImagesGrey_pca = pca.fit_transform(trainingImagesGrey)\n",
        "testingImagesGrey_pca = pca.transform(testingImagesGrey)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9XmpjbNEYweL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get labels for each image. \n",
        "\n",
        "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))\n",
        "le = MultiLabelBinarizer()\n",
        "yGenres = le.fit_transform(dataTraining['genres'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6GmXFAF5YweO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creates datasets for training and testing.   \n",
        "xTrainImaGrey, xValidationImaGrey, yTrainImaGrey, yValidationImaGrey = train_test_split(trainingImagesGrey_pca, yGenres, test_size=0.2, random_state=22)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scz9JWTdYweQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Images Models"
      ]
    },
    {
      "metadata": {
        "id": "GTjKmQcqrvfq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "metadata": {
        "id": "iPTaHg-lYweR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "a9136ab2-94e0-40a4-9e72-621da3d7ce0d"
      },
      "cell_type": "code",
      "source": [
        "# Creates a random forest classifier. \n",
        "\n",
        "mcRandomIma = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=20, random_state=22,verbose=0))\n",
        "\n",
        "# Train the model. \n",
        "\n",
        "mcRandomIma.fit(xTrainImaGrey,  yTrainImaGrey)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
              "            oob_score=False, random_state=22, verbose=0, warm_start=False),\n",
              "          n_jobs=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "jy4qrgIXYweX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e78b8aa5-ad3d-4a63-f4b7-610fc93e8228"
      },
      "cell_type": "code",
      "source": [
        "# Score the AUC over the test set. \n",
        "\n",
        "y_pred_genres = mcRandomIma.predict_proba(xValidationImaGrey)\n",
        "\n",
        "mcRandomIma_AUC=roc_auc_score(yValidationImaGrey, y_pred_genres, average='macro')\n",
        "\n",
        "print('Random Forest model score is: ' , mcRandomIma_AUC , 'AUC.')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest model score is:  0.5696614483536034 AUC.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pbT_1SAKvwjc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gradient Boost Classifier"
      ]
    },
    {
      "metadata": {
        "id": "0_idz2U2vwjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "ea54cf00-104b-4e63-cab0-6b0604447958"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Creates a random forest classifier. \n",
        "\n",
        "mcGradientIma = OneVsRestClassifier(GradientBoostingClassifier(n_estimators=100, max_depth=20, random_state=22,verbose=0))\n",
        "\n",
        "# Train the model. \n",
        "\n",
        "mcGradientIma.fit(xTrainImaGrey,  yTrainImaGrey)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
              "              learning_rate=0.1, loss='deviance', max_depth=20,\n",
              "              max_features=None, max_leaf_nodes=None,\n",
              "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "              min_samples_leaf=1, min_samples_split=2,\n",
              "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "              presort='auto', random_state=22, subsample=1.0, verbose=0,\n",
              "              warm_start=False),\n",
              "          n_jobs=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "Ja7RwNm6vwjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0b8c7351-0442-4db9-a4f4-32f8fcf77a1c"
      },
      "cell_type": "code",
      "source": [
        "# Score the AUC over the test set. \n",
        "\n",
        "y_pred_genres = mcGradientIma.predict_proba(xValidationImaGrey)\n",
        "\n",
        "mcGradientIma_AUC=roc_auc_score(yValidationImaGrey, y_pred_genres, average='macro')\n",
        "\n",
        "print('Random Forest model score is: ' , mcGradientIma_AUC , 'AUC.')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest model score is:  0.5579683680093176 AUC.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A4IW3pqJEX4B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Read Text"
      ]
    },
    {
      "metadata": {
        "id": "oGhBdtphEX4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d9903fd8-1c59-4a8e-e636-76ae6a345efe"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "maxWords= 5000\n",
        "\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=maxWords)\n",
        "\n",
        "tokenText = vectorizer.fit_transform(dataTraining['plot'])\n",
        "testingText = vectorizer.fit_transform(dataTesting['plot'])\n",
        "tokenText.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7895, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "AfhTJc8tEX4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a1cf9bb7-0061-4639-8838-b7744f2bc0c8"
      },
      "cell_type": "code",
      "source": [
        "# Creates datasets for training and testing.   \n",
        "xTrainTxt, xValidationTxt, yTrainTxt, yValidationTxt = train_test_split(tokenText, yGenres, test_size=0.20, random_state=22)\n",
        "xTrainTxt.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6316, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "HSkMJCj4EX4O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning  Text Models"
      ]
    },
    {
      "metadata": {
        "id": "Is1QvzU2EX4O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ]
    },
    {
      "metadata": {
        "id": "l2EFmWCLEX4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "58d20121-60a4-45dc-cdde-fba44c9cb4a7"
      },
      "cell_type": "code",
      "source": [
        "# Creates a random forest classifier. \n",
        "\n",
        "mcRandomTxt = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=10, random_state=22,verbose=0))\n",
        "\n",
        "# Train the model. \n",
        "\n",
        "mcRandomTxt.fit(xTrainTxt,  yTrainTxt)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
              "            oob_score=False, random_state=22, verbose=0, warm_start=False),\n",
              "          n_jobs=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "0-C33whhEX4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "76607732-6789-4855-b915-ba6e72dc54d2"
      },
      "cell_type": "code",
      "source": [
        "# Score the AUC over the test set. \n",
        "\n",
        "y_pred_genres = mcRandomTxt.predict_proba(xValidationTxt)\n",
        "\n",
        "mcRandomTxt_AUC = roc_auc_score(yValidationTxt, y_pred_genres, average='macro')\n",
        "\n",
        "print('Random Forest model score is: ' ,mcRandomTxt_AUC, 'AUC.')\n",
        "\n",
        "yPredTestRF = mcRandomTxt.predict_proba(testingText)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest model score is:  0.8155028010105557 AUC.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h_3VzblkEX4V",
        "colab_type": "code",
        "colab": {},
        "outputId": "d90eb6f7-2b65-4614-d559-081e93a4713a"
      },
      "cell_type": "code",
      "source": [
        "# Print prediction for test (kaggle) data. \n",
        "\n",
        "yPredTestRF = mcRandomTxt.predict_proba(testingText)\n",
        "\n",
        "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
        "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
        "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
        "\n",
        "pd.DataFrame(yPredTest, index=dataTesting.index, columns=cols).to_csv('pred_genres_RF_Text.csv', index_label='ID')\n",
        "\n",
        "print('Results were printed.....')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results were printed.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DBqsD4_UEX4c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting"
      ]
    },
    {
      "metadata": {
        "id": "BiciPU-vEX4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "1509859d-f302-44c7-8358-88edf63f5f3d"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Creates a GradientBoostingClassifier. \n",
        "\n",
        "mcGradientTxt = OneVsRestClassifier(GradientBoostingClassifier(n_estimators=100, max_depth=10, random_state=22,verbose=0))\n",
        "\n",
        "# Train the model. \n",
        "\n",
        "mcGradientTxt.fit(xTrainTxt,  yTrainTxt)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
              "              learning_rate=0.1, loss='deviance', max_depth=10,\n",
              "              max_features=None, max_leaf_nodes=None,\n",
              "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "              min_samples_leaf=1, min_samples_split=2,\n",
              "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "              presort='auto', random_state=22, subsample=1.0, verbose=0,\n",
              "              warm_start=False),\n",
              "          n_jobs=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "eLU3w3r5EX4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2a602643-f67b-4279-9dce-a65fd7eb7bb1"
      },
      "cell_type": "code",
      "source": [
        "# Score the AUC over the test set. \n",
        "\n",
        "y_pred_genres = mcGradientTxt.predict_proba(xValidationTxt)\n",
        "\n",
        "mcGradientTxt_AUC = roc_auc_score(yValidationTxt, y_pred_genres, average='macro')\n",
        "\n",
        "print('Gradient Boosting score is: ' ,mcGradientTxt_AUC, 'AUC.')\n",
        "\n",
        "yPredTestGB = mcGradientTxt.predict_proba(testingText)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient Boosting score is:  0.7651230922952764 AUC.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4vFbSWqoEX4h",
        "colab_type": "code",
        "colab": {},
        "outputId": "50eaf072-6a84-4844-f8c3-c3eb75cf5bb8"
      },
      "cell_type": "code",
      "source": [
        "# Print prediction for test (kaggle) data. \n",
        "\n",
        "yPredTestGB = mcGradientTxt.predict_proba(testingText)\n",
        "\n",
        "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
        "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
        "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
        "\n",
        "pd.DataFrame(yPredTest, index=dataTesting.index, columns=cols).to_csv('pred_genres_GB_Text.csv', index_label='ID')\n",
        "\n",
        "print('Results were printed.....')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results were printed.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gAakAm1kEX4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xtest=  np.c_[yPredTestRF,yPredTestGB]\n",
        "xtest.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ga4EJU4IEX4_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stacking Model"
      ]
    },
    {
      "metadata": {
        "id": "JZD99wWbEX5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from google.colab import files\n",
        "#predGbText= mcGradientTxt.predict_proba(xValidationTxt)\n",
        "predRfText= mcRandomTxt.predict_proba(xValidationTxt)\n",
        "y_pred_genres = mcRandomIma.predict_proba(xValidationImaGrey)\n",
        "yPredTestImaRF= mcRandomIma.predict_proba(testingImagesGrey_pca)\n",
        "\n",
        "\n",
        "mixText =  np.c_[predRfText,y_pred_genres]\n",
        "Xtest =  np.c_[yPredTestRF,yPredTestImaRF]\n",
        "\n",
        "clf_etc = OneVsRestClassifier(ExtraTreesClassifier(n_jobs=-1, n_estimators=400, max_depth=6, random_state=42))\n",
        "clf_etc.fit(mixText, yValidationTxt)\n",
        "y_pred_genres_etc = clf_etc.predict_proba(Xtest)\n",
        "#acc_etc=roc_auc_score(yValidationTxt, y_pred_genres_etc, average='macro')\n",
        "\n",
        "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
        "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
        "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
        "\n",
        "pd.DataFrame(y_pred_genres_etc, index=dataTesting.index, columns=cols).to_csv('pred_genres_Stack1.csv', index_label='ID')\n",
        "#print(\"Stacking  AUC:\",acc_etc)\n",
        "\n",
        "files.download('pred_genres_Stack1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7kMu86hGEX5D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "mixModel = Sequential()\n",
        "mixModel.add(Dense(64, input_shape=(mixText.shape[1],)))\n",
        "mixModel.add(Activation('tanh'))\n",
        "#mixModel.add(BatchNormalization())\n",
        "mixModel.add(Dropout(0.5))\n",
        "mixModel.add(Dense(24, activation='sigmoid'))\n",
        "mixModel.summary()\n",
        "\n",
        "mixModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opts.adam(lr=0.001), \n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "batch_size = 5000\n",
        "\n",
        "mixModel.fit(mixText,yValidationStack, \n",
        "             epochs = 100,\n",
        "             verbose = 2,\n",
        "             batch_size=batch_size, \n",
        "             validation_data=[xValidationTxt,yValidationTxt],\n",
        "             callbacks=[PlotLossesKeras()])\n",
        "\n",
        "mixModel.save('mixNNtrained.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1sfD4vRdYwej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
